{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This assignment is an exercise in working with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(ranger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data and fixing any variable types that were loaded incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5960 obs. of  13 variables:\n",
      " $ BAD    : int  1 1 1 1 0 1 1 1 1 1 ...\n",
      " $ LOAN   : int  1100 1300 1500 1500 1700 1700 1800 1800 2000 2000 ...\n",
      " $ MORTDUE: num  25860 70053 13500 NA 97800 ...\n",
      " $ VALUE  : num  39025 68400 16700 NA 112000 ...\n",
      " $ REASON : Factor w/ 3 levels \"\",\"DebtCon\",\"HomeImp\": 3 3 3 1 3 3 3 3 3 3 ...\n",
      " $ JOB    : Factor w/ 7 levels \"\",\"Mgr\",\"Office\",..: 4 4 4 1 3 4 4 4 4 6 ...\n",
      " $ YOJ    : num  10.5 7 4 NA 3 9 5 11 3 16 ...\n",
      " $ DEROG  : int  0 0 0 NA 0 0 3 0 0 0 ...\n",
      " $ DELINQ : int  0 2 0 NA 0 0 2 0 2 0 ...\n",
      " $ CLAGE  : num  94.4 121.8 149.5 NA 93.3 ...\n",
      " $ NINQ   : int  1 0 1 NA 0 1 1 0 1 0 ...\n",
      " $ CLNO   : int  9 14 10 NA 14 8 17 8 12 13 ...\n",
      " $ DEBTINC: num  NA NA NA NA NA ...\n"
     ]
    }
   ],
   "source": [
    "hmeq = read.csv('hmeq.csv')\n",
    "str(hmeq)\n",
    "\n",
    "hmeq$BAD=as.factor(hmeq$BAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly cleaned the data to handle missing values and renamed the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4740"
      ],
      "text/latex": [
       "4740"
      ],
      "text/markdown": [
       "4740"
      ],
      "text/plain": [
       "[1] 4740"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " BAD           LOAN          MORTDUE           VALUE            REASON    \n",
       " 0:4771   Min.   : 1100   Min.   :  2063   Min.   :  8000          : 252  \n",
       " 1:1189   1st Qu.:11100   1st Qu.: 46276   1st Qu.: 66076   DebtCon:3928  \n",
       "          Median :16300   Median : 65019   Median : 89236   HomeImp:1780  \n",
       "          Mean   :18608   Mean   : 73761   Mean   :101776                 \n",
       "          3rd Qu.:23300   3rd Qu.: 91488   3rd Qu.:119824                 \n",
       "          Max.   :89900   Max.   :399550   Max.   :855909                 \n",
       "                          NA's   :518      NA's   :112                    \n",
       "      JOB            YOJ             DEROG             DELINQ       \n",
       "        : 279   Min.   : 0.000   Min.   : 0.0000   Min.   : 0.0000  \n",
       " Mgr    : 767   1st Qu.: 3.000   1st Qu.: 0.0000   1st Qu.: 0.0000  \n",
       " Office : 948   Median : 7.000   Median : 0.0000   Median : 0.0000  \n",
       " Other  :2388   Mean   : 8.922   Mean   : 0.2546   Mean   : 0.4494  \n",
       " ProfExe:1276   3rd Qu.:13.000   3rd Qu.: 0.0000   3rd Qu.: 0.0000  \n",
       " Sales  : 109   Max.   :41.000   Max.   :10.0000   Max.   :15.0000  \n",
       " Self   : 193   NA's   :515      NA's   :708       NA's   :580      \n",
       "     CLAGE             NINQ             CLNO         DEBTINC        \n",
       " Min.   :   0.0   Min.   : 0.000   Min.   : 0.0   Min.   :  0.5245  \n",
       " 1st Qu.: 115.1   1st Qu.: 0.000   1st Qu.:15.0   1st Qu.: 29.1400  \n",
       " Median : 173.5   Median : 1.000   Median :20.0   Median : 34.8183  \n",
       " Mean   : 179.8   Mean   : 1.186   Mean   :21.3   Mean   : 33.7799  \n",
       " 3rd Qu.: 231.6   3rd Qu.: 2.000   3rd Qu.:26.0   3rd Qu.: 39.0031  \n",
       " Max.   :1168.2   Max.   :17.000   Max.   :71.0   Max.   :203.3121  \n",
       " NA's   :308      NA's   :510      NA's   :222    NA's   :1267      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3364"
      ],
      "text/latex": [
       "3364"
      ],
      "text/markdown": [
       "3364"
      ],
      "text/plain": [
       "[1] 3364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(is.na(hmeq))\n",
    "summary(hmeq)\n",
    "hmeq[hmeq=='']=NA\n",
    "hmeq_complete=hmeq[complete.cases(hmeq),]\n",
    "nrow(hmeq_complete)\n",
    "\n",
    "names(hmeq_complete)[1]='target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 70% training, 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2018)\n",
    "splitIndex=createDataPartition(hmeq_complete$target, p=.70, list=FALSE, times=1)\n",
    "train_hmeq=hmeq_complete[splitIndex,]\n",
    "test=hmeq_complete[-splitIndex,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test random forest (ranger).  Report the misclassification/accuracy and balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.946481665014866"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.946481665014866"
      ],
      "text/markdown": [
       "**Accuracy:** 0.946481665014866"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.9464817 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Balanced Accuracy:</strong> 0.7"
      ],
      "text/latex": [
       "\\textbf{Balanced Accuracy:} 0.7"
      ],
      "text/markdown": [
       "**Balanced Accuracy:** 0.7"
      ],
      "text/plain": [
       "Balanced Accuracy \n",
       "              0.7 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest1=ranger(target~.,data=train_hmeq)\n",
    "pred=predict(forest1,data=test)$predictions\n",
    "cm=confusionMatrix(pred,test$target,positive=\"1\")\n",
    "cm$overall['Accuracy']\n",
    "cm$byClass['Balanced Accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of Default: Non-Default clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "         0          1 \n",
       "0.91082803 0.08917197 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.table(table(train_hmeq$target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the data using undersampling and rerunning the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "  0 210 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2145    0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Balanced Accuracy:</strong> 0.832221013178576"
      ],
      "text/latex": [
       "\\textbf{Balanced Accuracy:} 0.832221013178576"
      ],
      "text/markdown": [
       "**Balanced Accuracy:** 0.832221013178576"
      ],
      "text/plain": [
       "Balanced Accuracy \n",
       "         0.832221 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train1=train_hmeq[train_hmeq$target==\"1\",]\n",
    "n1=nrow(train1)\n",
    "table(train1$target)\n",
    "\n",
    "train0=train_hmeq[train_hmeq$target==\"0\",]\n",
    "n0=nrow(train0)\n",
    "table(train0$target)\n",
    "\n",
    "train00=train0[sample(1:n0,n1),]\n",
    "\n",
    "train_under=rbind(train00,train1)\n",
    "\n",
    "model_under=ranger(target~.,data=train_under)\n",
    "pred_under=predict(model_under,data=test)$predictions\n",
    "cm_under=confusionMatrix(pred_under,test$target,positive=\"1\")\n",
    "cm_under$byClass['Balanced Accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance the data using oversampling and rerunning the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Balanced Accuracy:</strong> 0.721134082940394"
      ],
      "text/latex": [
       "\\textbf{Balanced Accuracy:} 0.721134082940394"
      ],
      "text/markdown": [
       "**Balanced Accuracy:** 0.721134082940394"
      ],
      "text/plain": [
       "Balanced Accuracy \n",
       "        0.7211341 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train11=train1[sample(1:n1,n0,replace = TRUE),]\n",
    "\n",
    "train_over=rbind(train11,train0)\n",
    "\n",
    "model_over=ranger(target~.,data=train_over)\n",
    "pred_over=predict(model_over,data=test)$predictions\n",
    "cm_over=confusionMatrix(pred_over,test$target,positive=\"1\")\n",
    "cm_over$byClass['Balanced Accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function that takes a dataset argument with a target variable named target and a method argument specifying undersampling or oversampling, then outputs a dataset with a balanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "210 210 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_bal=function(x,method){\n",
    "  train1=x[x[,'target']==\"1\",]\n",
    "  n1=nrow(train1)\n",
    "  table(train1$target)\n",
    "  \n",
    "  train0=x[x[,'target']==\"0\",]\n",
    "  n0=nrow(train0)\n",
    "  table(train0$target)\n",
    "  \n",
    "  if (method==\"over\"){\n",
    "    train11=train1[sample(1:n1,n0,replace = TRUE),]\n",
    "    train_over=rbind(train11,train0)\n",
    "  }\n",
    "  else if (method==\"under\"){\n",
    "    train00=train0[sample(1:n0,n1),]\n",
    "    train_under=rbind(train00,train1)\n",
    "  }\n",
    "  else{\n",
    "    print(\"Please input either under or over for the method parameter\")\n",
    "  }\n",
    "}\n",
    "train_bal=quick_bal(train_hmeq,\"under\")\n",
    "table(train_bal$target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function that takes a dataset with a target variable named target and outputs the balanced accuracies of random forests with both undersampling and oversampling being applied on the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Undersample:\"\n",
      "Balanced Accuracy \n",
      "        0.8301596 \n",
      "[1] \"Oversample:\"\n",
      "Balanced Accuracy \n",
      "        0.7544674 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Balanced Accuracy:</strong> 0.754467416273727"
      ],
      "text/latex": [
       "\\textbf{Balanced Accuracy:} 0.754467416273727"
      ],
      "text/markdown": [
       "**Balanced Accuracy:** 0.754467416273727"
      ],
      "text/plain": [
       "Balanced Accuracy \n",
       "        0.7544674 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_model_bal=function(x){\n",
    "  train1=x[x[,'target']==\"1\",]\n",
    "  n1=nrow(train1)\n",
    "  table(train1$target)\n",
    "  \n",
    "  train0=x[x[,'target']==\"0\",]\n",
    "  n0=nrow(train0)\n",
    "  table(train0$target)\n",
    "  \n",
    "  print(\"Undersample:\")\n",
    "  train00=train0[sample(1:n0,n1),]\n",
    "  train_under=rbind(train00,train1)\n",
    "  model_under=ranger(target~.,data=train_under)\n",
    "  pred_under=predict(model_under,data=test)$predictions\n",
    "  cm_under=confusionMatrix(pred_under,test$target,positive=\"1\")\n",
    "  print(cm_under$byClass['Balanced Accuracy'])\n",
    "  \n",
    "  print(\"Oversample:\")\n",
    "  train11=train1[sample(1:n1,n0,replace = TRUE),]\n",
    "  train_over=rbind(train11,train0)\n",
    "  model_over=ranger(target~.,data=train_over)\n",
    "  pred_over=predict(model_over,data=test)$predictions\n",
    "  cm_over=confusionMatrix(pred_over,test$target,positive=\"1\")\n",
    "  print(cm_over$byClass['Balanced Accuracy'])\n",
    "  \n",
    "}\n",
    "train_model_bal=quick_model_bal(train_hmeq)\n",
    "train_model_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
